# ===== Ollama Endpoint =====
# Leave empty to use default (http://localhost:11434).
# If running in WSL, setting this to empty allows auto-detection of the Windows host IP.
OLLAMA_URL=

# Disable WSL host-IP auto-detection (keep localhost as-is).
# Set to 1 if detection picks a bad IP or you run Ollama inside WSL.
OLLAMA_SKIP_WSL_IP_DETECT=0


# ===== Global Model Defaults =====
# These are used as fallbacks if no specific tool model is set.
# Useful to switch the baseline model for everything.
DEFAULT_LLM_MODEL=llama3.1:8b
DEFAULT_VLM_MODEL=qwen2.5vl:7b


# ===== Tool-Specific LLM Models =====
# Leave empty to use the DEFAULT_LLM_MODEL (or system default).

# Used by: scripts/investigate.py
INVESTIGATE_MODEL=

# Used by: scripts/explain.py
EXPLAIN_MODEL=

# Used by: scripts/ai_commit.py
AI_COMMIT_MODEL=

# Used by: scripts/smart_parse.py
SMART_PARSE_MODEL=

# Used by: scripts/english_teacher.py
ENGLISH_TEACHER_MODEL=


# ===== Vision / Screenshots (screen_explain) =====
# Directory to scan for screenshots
SCREENSHOT_DIR="/mnt/c/Users/xxx/OneDrive/Pictures"

# Specific model for screen_explain (overrides DEFAULT_VLM_MODEL)
SCREEN_EXPLAIN_MODEL=

# Debugging & Verbosity
VLM_DEBUG=0
VLM_VERBOSE=1
VLM_QUIET=0
VLM_USE_RICH=1

# Advanced VLM Tuning
# VLM_TIMEOUT=180
# VLM_MAX_CTX=4096
# VLM_JPEG_QUALITY=85
# VLM_SNAP_MULT=32
# VLM_SNAP_MIN=64
# VLM_NUM_BATCH=16
VLM_NUM_PREDICT=512


# ===== Speech-to-Text (faster-whisper) =====
WHISPER_MODEL=small
WHISPER_LANG=en
# Force device: cpu or cuda
WHISPER_DEVICE=cpu
# Compute precision: int8, int8_float16, float16
WHISPER_COMPUTE_TYPE=int8


# ===== English Teacher Config =====
ENGLISH_TEACHER_NUM_CTX=4096
ENGLISH_TEACHER_TIMEOUT=60
# Mode: coach, strict, or correct
ENGLISH_TEACHER_MODE=coach


# ===== Investigate / Explain Extras =====
# Use a custom log file instead of repo/logs/investigate-last.log
# INVESTIGATE_LOG=


# ===== Shared LLM settings =====
# Soft warning threshold for context size (not a hard limit)
LLM_SOFT_CONTEXT_LIMIT=40000


# ===== FastAPI Server =====
API_HOST=127.0.0.1
API_PORT=8008


# ===== Postgres =====
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/ai_scripts